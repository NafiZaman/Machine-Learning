{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2e07940-f984-4591-a7a5-3fd1b332fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "be52858d-3699-4ff7-ad87-34fc1ae0da98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:\n",
      "tensor([2])\n",
      "\n",
      "preds:\n",
      "tensor([[0.2072, 0.2699, 0.5507]])\n",
      "\n",
      "loss: 0.9019474983215332\n",
      "\n",
      "my loss:---------------------------.\n",
      "\n",
      "losses:\n",
      "tensor([[1.2455, 1.1828, 0.9019]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "target = torch.randint(0, 3, (1, 1)).squeeze(0)\n",
    "preds = torch.randn(1, 3)\n",
    "\n",
    "print(\"target:\")\n",
    "print(target)\n",
    "\n",
    "print()\n",
    "print(\"preds:\")\n",
    "print(preds)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "loss = loss_func(preds, target)\n",
    "\n",
    "print()\n",
    "print(\"loss:\", loss.item())\n",
    "\n",
    "print()\n",
    "print(\"my loss:---------------------------.\")\n",
    "\n",
    "# print()\n",
    "# print(\"preds in one row:\")\n",
    "# preds = torch.sum(preds, dim = -1)\n",
    "# print(preds)\n",
    "\n",
    "# print()\n",
    "# print(\"exp:\")\n",
    "# print(torch.exp(preds))\n",
    "\n",
    "# print()\n",
    "# print(\"exp sum:\")\n",
    "# print(torch.sum(torch.exp(preds)))\n",
    "\n",
    "# print()\n",
    "# print(\"log of exp sum:\")\n",
    "# print(torch.log(torch.sum(torch.exp(preds))))\n",
    "\n",
    "print()\n",
    "print(\"losses:\")\n",
    "print(-preds + torch.log(torch.sum(torch.exp(preds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "647be279-a970-4182-903c-0a2fc219900a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:\n",
      "tensor([2, 0])\n",
      "\n",
      "preds:\n",
      "tensor([[-0.2905, -1.0704,  1.2645],\n",
      "        [-0.6874,  0.1604, -0.6065]])\n",
      "\n",
      "loss: 0.8772002458572388\n",
      "\n",
      "losses:\n",
      "tensor([[2.2153, 2.9952, 0.6604],\n",
      "        [2.6123, 1.7645, 2.5313]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "target = torch.randint(0, 3, (1, 2)).squeeze(0)\n",
    "preds = torch.randn(2, 3)\n",
    "\n",
    "print(\"target:\")\n",
    "print(target)\n",
    "\n",
    "print()\n",
    "print(\"preds:\")\n",
    "print(preds)\n",
    "\n",
    "loss = loss_func(preds, target)\n",
    "\n",
    "print()\n",
    "print(\"loss:\", loss.item())\n",
    "\n",
    "print()\n",
    "print(\"losses:\")\n",
    "print(-preds + torch.log(torch.sum(torch.exp(preds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "60ea3b43-a0b3-4772-9bd5-81e07fece17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.024744987487793\n",
      "\n",
      "tensor([[  54.5981, 2980.9580,   20.0855]])\n",
      "tensor(3055.6416)\n",
      "tensor(8.0247)\n",
      "tensor([[4.0247, 0.0247, 5.0247]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.Tensor([[4, 8, 3]])\n",
    "y=torch.Tensor([2.]).long()\n",
    "\n",
    "loss = loss_func(a, y)\n",
    "print(\"loss:\",loss.item())\n",
    "\n",
    "print()\n",
    "print(torch.exp(a))\n",
    "print(torch.sum(torch.exp(a)))\n",
    "print(torch.log(torch.sum(torch.exp(a))))\n",
    "print(-a + torch.log(torch.sum(torch.exp(a))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "2a473351-55f0-49bc-b402-fb5b61064cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:\n",
      "tensor([[0.8800, 0.1200],\n",
      "        [0.5100, 0.4900]])\n",
      "target:\n",
      "tensor([1, 0])\n",
      "\n",
      "output from loss with log input: tensor(1.3968)\n",
      "above output with manual calculation: tensor(1.3968)\n",
      "\n",
      "output from loss without log input: tensor(0.9134)\n",
      "logsoftmax_output:\n",
      "tensor([[-0.3837, -1.1437],\n",
      "        [-0.6832, -0.7032]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "a = torch.tensor(([0.88, 0.12], [0.51, 0.49]), dtype = torch.float)\n",
    "print(\"pred:\")\n",
    "print(a)\n",
    "target = torch.tensor([1, 0])\n",
    "print(\"target:\")\n",
    "print(target)\n",
    "print()\n",
    "\n",
    "output = loss(torch.log(a), target)\n",
    "\n",
    "print(\"output from loss with log input:\", output)\n",
    "print(\"above output with manual calculation:\", (-torch.log(a[0, 1]) - torch.log(a[1, 0])) / 2)\n",
    "\n",
    "print()\n",
    "output = loss(a, target)\n",
    "print(\"output from loss without log input:\", output)\n",
    "\n",
    "# print(torch.log(a))\n",
    "# print((-a[0, 1] - a[1, 0]) / 2)\n",
    "logsoftmax_func=nn.LogSoftmax(dim=1)\n",
    "logsoftmax_output=logsoftmax_func(a)\n",
    "print('logsoftmax_output:')\n",
    "print(logsoftmax_output)\n",
    "\n",
    "# print(\"above output with manual calculation:\", (-torch.log(a[0, 1]) - torch.log(a[1, 0])) / 2)\n",
    "# output = loss(F.log_softmax(a, dim =1), target)\n",
    "# print(\"output from loss:\", output)\n",
    "\n",
    "# print((-torch.log(a[0, 1]) - torch.log(a[1, 0])) / 2)\n",
    "# print()\n",
    "# print(torch.log(a[0, 1]))\n",
    "# print(torch.log(a[1, 0]))\n",
    "\n",
    "# print(torch.log(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "3132ff61-e213-4035-81c2-86b6068cea79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_input:\n",
      " tensor([[ 1.5410, -0.2934, -2.1788],\n",
      "        [ 0.5684, -1.0845, -1.3986],\n",
      "        [ 0.4033,  0.8380, -0.7193]])\n",
      "soft_output:\n",
      " tensor([[0.8446, 0.1349, 0.0205],\n",
      "        [0.7511, 0.1438, 0.1051],\n",
      "        [0.3484, 0.5382, 0.1134]])\n",
      "log_output:\n",
      " tensor([[-0.1689, -2.0033, -3.8886],\n",
      "        [-0.2862, -1.9392, -2.2532],\n",
      "        [-1.0543, -0.6196, -2.1769]])\n",
      "logsoftmax_output:\n",
      " tensor([[-0.1689, -2.0033, -3.8886],\n",
      "        [-0.2862, -1.9392, -2.2532],\n",
      "        [-1.0543, -0.6196, -2.1769]])\n",
      "nlloss_output:\n",
      " tensor(1.7703)\n",
      "crossentropyloss_output:\n",
      " tensor(1.7703)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "x_input=torch.randn(3,3)#Generate input randomly\n",
    "print('x_input:\\n',x_input)\n",
    "y_target=torch.tensor([1,2,0])#Set the output specific value print('y_target\\n',y_target)\n",
    " \n",
    " #Calculate the input softmax, at this time you can see that each row is added together and the result is 1\n",
    "softmax_func=nn.Softmax(dim=1)\n",
    "soft_output=softmax_func(x_input)\n",
    "print('soft_output:\\n',soft_output)\n",
    " \n",
    " #Take log on the basis of softmax\n",
    "log_output=torch.log(soft_output)\n",
    "print('log_output:\\n',log_output)\n",
    " \n",
    " #Compare the combination of softmax and log with the output results of nn.LogSoftmaxloss (negative log-likelihood loss), and find that the two are consistent.\n",
    "logsoftmax_func=nn.LogSoftmax(dim=1)\n",
    "logsoftmax_output=logsoftmax_func(x_input)\n",
    "print('logsoftmax_output:\\n',logsoftmax_output)\n",
    " \n",
    "#The default parameter configuration of NLLLoss in #pytorch is: reducetion=True, size_average=True\n",
    "nllloss_func=nn.NLLLoss()\n",
    "nlloss_output=nllloss_func(logsoftmax_output,y_target)\n",
    "print('nlloss_output:\\n',nlloss_output)\n",
    " \n",
    " #Use loss_func=nn.CrossEntropyLoss() in pytorch directly to see if it is the same as the calculation after NLLLoss\n",
    "crossentropyloss=nn.CrossEntropyLoss()\n",
    "crossentropyloss_output=crossentropyloss(x_input,y_target)\n",
    "print('crossentropyloss_output:\\n',crossentropyloss_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "ad06ab72-5dbc-4e22-ae4d-161eb1a72ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "tensor([[0.8800, 0.1200],\n",
      "        [0.5100, 0.4900]])\n",
      "target:\n",
      "tensor([1, 0])\n",
      "\n",
      "x_log_softmax:\n",
      "tensor([[-0.3837, -1.1437],\n",
      "        [-0.6832, -0.7032]])\n",
      "\n",
      "nllloss with x_log_softmax and target: tensor(0.9134)\n",
      "cross entropy loss  with x and target: tensor(0.9134)\n",
      "----------------------------------------------------\n",
      "log of x:\n",
      "tensor([[-0.1278, -2.1203],\n",
      "        [-0.6733, -0.7133]])\n",
      "tensor(1.3968)\n",
      "tensor(1.3968)\n",
      "tensor(1.3968)\n",
      "nllloss with x_log_softmax and target tensor(-0.3150)\n"
     ]
    }
   ],
   "source": [
    "cel_func = nn.CrossEntropyLoss()\n",
    "x = torch.tensor(([0.88, 0.12], [0.51, 0.49]), dtype = torch.float)\n",
    "print(\"x:\")\n",
    "print(x)\n",
    "target = torch.tensor([1, 0])\n",
    "print(\"target:\")\n",
    "print(target)\n",
    "print()\n",
    "\n",
    "x_log_softmax = F.log_softmax(x, dim = 1)\n",
    "print(\"x_log_softmax:\")\n",
    "print(x_log_softmax)\n",
    "\n",
    "nllloss_func = nn.NLLLoss()\n",
    "\n",
    "loss1 = nllloss_func(x_log_softmax, target)\n",
    "\n",
    "print()\n",
    "print(\"nllloss with x_log_softmax and target:\",loss1)\n",
    "cel = cel_func(x, target)\n",
    "print(\"cross entropy loss  with x and target:\", cel)\n",
    "\n",
    "print(\"----------------------------------------------------\")\n",
    "foo = torch.log(x)\n",
    "# print(F.log_softmax(foo, 1))\n",
    "\n",
    "print(\"log of x:\")\n",
    "print(foo)\n",
    "print(nllloss_func(foo, target))\n",
    "print(cel_func(foo, target))\n",
    "# print()\n",
    "# print(\"log of x:\")\n",
    "# print(torch.log(x))\n",
    "# loss2 = nllloss_func(x, target)\n",
    "# print()\n",
    "# print(\"loss2:\",loss2)\n",
    "print((-torch.log(x[0, 1]) - torch.log(x[1, 0])) / 2)\n",
    "\n",
    "# print(loss_func(x, target))\n",
    "print(\"nllloss with x_log_softmax and target\", nllloss_func(x, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "7eda88bb-9d6d-4c7e-ae5e-b4df960bc8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:\n",
      "tensor([[ 1.5410, -0.2934],\n",
      "        [-2.1788,  0.5684]])\n",
      "\n",
      "targets:\n",
      "tensor([0, 1])\n",
      "\n",
      "preds_log_softmax:\n",
      "tensor([[-0.1482, -1.9826],\n",
      "        [-2.8094, -0.0621]])\n",
      "\n",
      "loss: tensor(0.1052)\n",
      "my loss: tensor(0.1052)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "preds = torch.randn(2, 2)\n",
    "\n",
    "print(\"preds:\")\n",
    "print(preds)\n",
    "\n",
    "targets = torch.tensor([0, 1])#torch.randint(0, 3, (1, 2)).squeeze(0)\n",
    "print()\n",
    "print(\"targets:\")\n",
    "print(targets)\n",
    "\n",
    "preds_log_softmax = F.log_softmax(preds, 1)\n",
    "print()\n",
    "print(\"preds_log_softmax:\")\n",
    "print(preds_log_softmax)\n",
    "\n",
    "loss = cel_func(preds, targets)\n",
    "print()\n",
    "print(\"loss:\", loss)\n",
    "\n",
    "my_loss = -(preds_log_softmax[0, 0] + preds_log_softmax[1, 1]) / 2 \n",
    "print(\"my loss:\", my_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5529e403-02f3-4ac6-a5b1-3a2d087b8d36",
   "metadata": {},
   "source": [
    "## This is the actual code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4d7ec3b-1c18-4845-9796-83e172408d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:\n",
      "tensor([[ 0.5294, -0.9531,  1.4040,  0.2094, -0.1232],\n",
      "        [ 0.3152,  0.0944,  0.2190,  0.5432,  0.6455],\n",
      "        [ 0.0643, -0.4395, -0.4782,  0.6193,  1.8131]])\n",
      "\n",
      "targets:\n",
      "tensor([2, 4, 1])\n",
      "\n",
      "PyTorch loss: tensor(1.6102)\n",
      "\n",
      "preds_log_softmax:\n",
      "tensor([[-1.5834, -3.0660, -0.7089, -1.9035, -2.2361],\n",
      "        [-1.6785, -1.8993, -1.7747, -1.4505, -1.3482],\n",
      "        [-2.2696, -2.7734, -2.8121, -1.7146, -0.5207]])\n",
      "\n",
      "my loss: tensor(1.6102)\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(1)\n",
    "\n",
    "preds = torch.randn(3, 5)\n",
    "print(\"preds:\")\n",
    "print(preds)\n",
    "\n",
    "targets = torch.randint(0, 5, (1, 3)).squeeze(0)\n",
    "print()\n",
    "print(\"targets:\")\n",
    "print(targets)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "loss = loss_func(preds, targets)\n",
    "print()\n",
    "print(\"PyTorch loss:\", loss)\n",
    "\n",
    "preds_log_softmax = F.log_softmax(preds, 1)\n",
    "print()\n",
    "print(\"preds_log_softmax:\")\n",
    "print(preds_log_softmax)\n",
    "\n",
    "my_loss = 0\n",
    "for i in range(targets.shape[0]):\n",
    "    my_loss += preds_log_softmax[i, targets[i].item()]\n",
    "    \n",
    "my_loss *= -1\n",
    "my_loss /= targets.shape[-1] \n",
    "print()\n",
    "print(\"my loss:\", my_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
