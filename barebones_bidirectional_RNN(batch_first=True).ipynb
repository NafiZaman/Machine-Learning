{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 8, 6],\n",
      "        [1, 4, 4]])\n",
      "x_emb\n",
      "tensor([[[ 0.1124,  0.6408,  0.4412],\n",
      "         [-1.4689, -1.5867,  1.2032],\n",
      "         [-0.2159,  0.7924, -0.2897]],\n",
      "\n",
      "        [[ 0.4372,  0.4913, -0.2041],\n",
      "         [-0.4927,  0.2484,  0.4397],\n",
      "         [-0.4927,  0.2484,  0.4397]]], grad_fn=<EmbeddingBackward>)\n",
      "weight_ih_l0 torch.Size([5, 3])\n",
      "weight_hh_l0 torch.Size([5, 5])\n",
      "weight_ih_l0_reverse torch.Size([5, 3])\n",
      "weight_hh_l0_reverse torch.Size([5, 5])\n",
      "Pytorch results:\n",
      "out:\n",
      "tensor([[[ 0.3606,  0.1887, -0.1284, -0.0933, -0.0897, -0.2995, -0.2097,\n",
      "           0.5120, -0.3699, -0.2247],\n",
      "         [ 0.1449,  0.0654,  0.0732,  0.6874,  0.3344,  0.3512, -0.8475,\n",
      "           0.1094,  0.9039, -0.3021],\n",
      "         [ 0.2900,  0.1927,  0.0584, -0.1282, -0.3534,  0.1210,  0.1893,\n",
      "           0.2093, -0.2455, -0.1848]],\n",
      "\n",
      "        [[ 0.0427,  0.0461, -0.0034, -0.2824, -0.0789, -0.2437,  0.2922,\n",
      "           0.0279, -0.4758,  0.1251],\n",
      "         [ 0.2271, -0.0165,  0.1382,  0.0907, -0.0504, -0.0109, -0.3373,\n",
      "           0.3782,  0.1597, -0.3190],\n",
      "         [ 0.3176,  0.1364,  0.0548,  0.2315, -0.1117,  0.2642, -0.3012,\n",
      "           0.2351,  0.2848, -0.2415]]], grad_fn=<TransposeBackward1>)\n",
      "\n",
      "hidden:\n",
      "tensor([[[ 0.2900,  0.1927,  0.0584, -0.1282, -0.3534],\n",
      "         [ 0.3176,  0.1364,  0.0548,  0.2315, -0.1117]],\n",
      "\n",
      "        [[-0.2995, -0.2097,  0.5120, -0.3699, -0.2247],\n",
      "         [-0.2437,  0.2922,  0.0279, -0.4758,  0.1251]]],\n",
      "       grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "x_data = torch.randint(1, 9, (2, 3))\n",
    "print(x_data)\n",
    "\n",
    "emb = nn.Embedding(9, 3)\n",
    "\n",
    "x_emb = emb(x_data)\n",
    "\n",
    "print(\"x_emb\")\n",
    "print(x_emb)\n",
    "\n",
    "rnn = nn.RNN(3, 5, batch_first = True, bidirectional=True, bias = False)\n",
    "\n",
    "for name, param in rnn.named_parameters():\n",
    "    print(name, param.shape)\n",
    "    \n",
    "# print(rnn.weight_hh_l0)\n",
    "# print()\n",
    "# print(rnn.weight_hh_l0_reverse)\n",
    "\n",
    "out, hidden = rnn(x_emb)\n",
    "print(\"Pytorch results:\")\n",
    "print(\"out:\")\n",
    "print(out)\n",
    "print()\n",
    "print(\"hidden:\")\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1124,  0.6408,  0.4412],\n",
      "         [ 0.4372,  0.4913, -0.2041]],\n",
      "\n",
      "        [[-1.4689, -1.5867,  1.2032],\n",
      "         [-0.4927,  0.2484,  0.4397]],\n",
      "\n",
      "        [[-0.2159,  0.7924, -0.2897],\n",
      "         [-0.4927,  0.2484,  0.4397]]], grad_fn=<PermuteBackward>)\n",
      "tensor([[[-0.4927,  0.2484,  0.4397],\n",
      "         [-0.2159,  0.7924, -0.2897]],\n",
      "\n",
      "        [[-0.4927,  0.2484,  0.4397],\n",
      "         [-1.4689, -1.5867,  1.2032]],\n",
      "\n",
      "        [[ 0.4372,  0.4913, -0.2041],\n",
      "         [ 0.1124,  0.6408,  0.4412]]], grad_fn=<FlipBackward>)\n",
      "Calculating the results from RNN in forward direction\n",
      "\n",
      "My out forward:\n",
      "tensor([[[ 0.3606,  0.1887, -0.1284, -0.0933, -0.0897],\n",
      "         [ 0.1449,  0.0654,  0.0732,  0.6874,  0.3344],\n",
      "         [ 0.2900,  0.1927,  0.0584, -0.1282, -0.3534]],\n",
      "\n",
      "        [[ 0.0427,  0.0461, -0.0034, -0.2824, -0.0789],\n",
      "         [ 0.2271, -0.0165,  0.1382,  0.0907, -0.0504],\n",
      "         [ 0.3176,  0.1364,  0.0548,  0.2315, -0.1117]]],\n",
      "       grad_fn=<PermuteBackward>)\n"
     ]
    }
   ],
   "source": [
    "my_x = x_emb.permute(1, 0, 2)\n",
    "print(my_x)\n",
    "\n",
    "my_x_reverse = torch.flip(my_x, [0, 1])\n",
    "print(my_x_reverse)\n",
    "\n",
    "tanh = nn.Tanh()\n",
    "\n",
    "wii = rnn.weight_ih_l0\n",
    "whh = rnn.weight_hh_l0\n",
    "\n",
    "print(\"Calculating the results from RNN in forward direction\")\n",
    "batch_size, seq_len, feat_len = x_emb.shape\n",
    "\n",
    "hiddens = []\n",
    "h_t = torch.zeros(batch_size, 5)\n",
    "for i in range(seq_len):\n",
    "    ii = my_x[i] @ torch.transpose(wii, 0, 1)\n",
    "    hh = h_t @ torch.transpose(whh, 0, 1)\n",
    "    \n",
    "    h_t = tanh(ii + hh)\n",
    "    \n",
    "    hiddens.append(h_t)\n",
    "\n",
    "my_out_forward = torch.stack(hiddens).permute(1, 0, 2)\n",
    "\n",
    "print()\n",
    "print(\"My out forward:\")\n",
    "print(my_out_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the results from RNN in backward direction\n",
      "\n",
      "My out forward:\n",
      "tensor([[[ 0.3606,  0.1887, -0.1284, -0.0933, -0.0897],\n",
      "         [ 0.1449,  0.0654,  0.0732,  0.6874,  0.3344],\n",
      "         [ 0.2900,  0.1927,  0.0584, -0.1282, -0.3534]],\n",
      "\n",
      "        [[ 0.0427,  0.0461, -0.0034, -0.2824, -0.0789],\n",
      "         [ 0.2271, -0.0165,  0.1382,  0.0907, -0.0504],\n",
      "         [ 0.3176,  0.1364,  0.0548,  0.2315, -0.1117]]],\n",
      "       grad_fn=<PermuteBackward>)\n",
      "\n",
      "My out bacward:\n",
      "tensor([[[-0.2995, -0.2097,  0.5120, -0.3699, -0.2247],\n",
      "         [ 0.3512, -0.8475,  0.1094,  0.9039, -0.3021],\n",
      "         [ 0.1210,  0.1893,  0.2093, -0.2455, -0.1848]],\n",
      "\n",
      "        [[-0.2437,  0.2922,  0.0279, -0.4758,  0.1251],\n",
      "         [-0.0109, -0.3373,  0.3782,  0.1597, -0.3190],\n",
      "         [ 0.2642, -0.3012,  0.2351,  0.2848, -0.2415]]],\n",
      "       grad_fn=<FlipBackward>)\n"
     ]
    }
   ],
   "source": [
    "wii_r = rnn.weight_ih_l0_reverse\n",
    "whh_r = rnn.weight_hh_l0_reverse\n",
    "\n",
    "print(\"Calculating the results from RNN in backward direction\")\n",
    "# batch_size, seq_len, feat_len = x_emb.shape\n",
    "\n",
    "hiddens = []\n",
    "h_t = torch.zeros(batch_size, 5)\n",
    "\n",
    "for i in range(seq_len):\n",
    "    ii = my_x_reverse[i] @ torch.transpose(wii_r, 0, 1)\n",
    "    hh = h_t @ torch.transpose(whh_r, 0, 1)\n",
    "    \n",
    "    h_t = tanh(ii + hh)\n",
    "    \n",
    "    hiddens.append(h_t)\n",
    "\n",
    "my_out_backward = torch.flip(torch.stack(hiddens).permute(1, 0, 2),[0, 1])\n",
    "\n",
    "# print()\n",
    "# print(\"My hiddens backward:\")\n",
    "# print(hiddens)\n",
    "\n",
    "print()\n",
    "print(\"My out forward:\")\n",
    "print(my_out_forward)\n",
    "print()\n",
    "print(\"My out bacward:\")\n",
    "print(my_out_backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch final output: \n",
      "tensor([[[ 0.3606,  0.1887, -0.1284, -0.0933, -0.0897, -0.2995, -0.2097,\n",
      "           0.5120, -0.3699, -0.2247],\n",
      "         [ 0.1449,  0.0654,  0.0732,  0.6874,  0.3344,  0.3512, -0.8475,\n",
      "           0.1094,  0.9039, -0.3021],\n",
      "         [ 0.2900,  0.1927,  0.0584, -0.1282, -0.3534,  0.1210,  0.1893,\n",
      "           0.2093, -0.2455, -0.1848]],\n",
      "\n",
      "        [[ 0.0427,  0.0461, -0.0034, -0.2824, -0.0789, -0.2437,  0.2922,\n",
      "           0.0279, -0.4758,  0.1251],\n",
      "         [ 0.2271, -0.0165,  0.1382,  0.0907, -0.0504, -0.0109, -0.3373,\n",
      "           0.3782,  0.1597, -0.3190],\n",
      "         [ 0.3176,  0.1364,  0.0548,  0.2315, -0.1117,  0.2642, -0.3012,\n",
      "           0.2351,  0.2848, -0.2415]]], grad_fn=<TransposeBackward1>)\n",
      "\n",
      "my final output: \n",
      "tensor([[[ 0.3606,  0.1887, -0.1284, -0.0933, -0.0897, -0.2995, -0.2097,\n",
      "           0.5120, -0.3699, -0.2247],\n",
      "         [ 0.1449,  0.0654,  0.0732,  0.6874,  0.3344,  0.3512, -0.8475,\n",
      "           0.1094,  0.9039, -0.3021],\n",
      "         [ 0.2900,  0.1927,  0.0584, -0.1282, -0.3534,  0.1210,  0.1893,\n",
      "           0.2093, -0.2455, -0.1848]],\n",
      "\n",
      "        [[ 0.0427,  0.0461, -0.0034, -0.2824, -0.0789, -0.2437,  0.2922,\n",
      "           0.0279, -0.4758,  0.1251],\n",
      "         [ 0.2271, -0.0165,  0.1382,  0.0907, -0.0504, -0.0109, -0.3373,\n",
      "           0.3782,  0.1597, -0.3190],\n",
      "         [ 0.3176,  0.1364,  0.0548,  0.2315, -0.1117,  0.2642, -0.3012,\n",
      "           0.2351,  0.2848, -0.2415]]], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Pytorch final output: \")\n",
    "print(out)\n",
    "\n",
    "my_final_output = torch.cat((my_out_forward, my_out_backward), -1)\n",
    "print()\n",
    "print(\"my final output: \")\n",
    "print(my_final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
