{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hjVGHAqJbdUE"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V2_g3uuSb2sL",
    "outputId": "9e2903ae-87a6-4c23-b178-8f70e26cc4d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "punct_regex = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lAJvhrAzb5NG"
   },
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self, token_to_idx=None):\n",
    " \n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    " \n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    " \n",
    "    def add_token(self, token):\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    " \n",
    "    def lookup_token(self, token):\n",
    "        return self._token_to_idx[token]\n",
    " \n",
    "    def lookup_index(self, index):\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    " \n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)\n",
    "\n",
    "    \n",
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    " \n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    " \n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    " \n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    " \n",
    "    def lookup_token(self, token):\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "\n",
    "        \n",
    "class NMTVectorizer(object):\n",
    "    def __init__(self, source_vocab, target_vocab, max_source_length, max_target_length):\n",
    "        self.source_vocab = source_vocab\n",
    "        self.target_vocab = target_vocab\n",
    "        \n",
    "        self.max_source_length = max_source_length\n",
    "        self.max_target_length = max_target_length        \n",
    "        \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, bitext_df):\n",
    "        source_vocab = SequenceVocabulary()\n",
    "        target_vocab = SequenceVocabulary()\n",
    "        \n",
    "        max_source_length = 0\n",
    "        max_target_length = 0\n",
    " \n",
    "        for _, row in bitext_df.iterrows():\n",
    "            source_tokens = punct_regex.tokenize(row[\"source_language\"])\n",
    "            if len(source_tokens) > max_source_length:\n",
    "                max_source_length = len(source_tokens)\n",
    "            for token in source_tokens:\n",
    "                source_vocab.add_token(token)\n",
    "            \n",
    "            target_tokens = punct_regex.tokenize(row[\"target_language\"])\n",
    "            if len(target_tokens) > max_target_length:\n",
    "                max_target_length = len(target_tokens)\n",
    "            for token in target_tokens:\n",
    "                target_vocab.add_token(token)\n",
    "            \n",
    "        return cls(source_vocab, target_vocab, max_source_length, max_target_length)\n",
    "    \n",
    "    def get_vector(self, text, source=True, target=False):\n",
    "        if source:\n",
    "            vocab = self.source_vocab\n",
    "            max_seq_len = self.max_source_length\n",
    "        else:\n",
    "            vocab = self.target_vocab\n",
    "            max_seq_len = self.max_target_length\n",
    "            \n",
    "        vector = np.zeros(max_seq_len + 2, dtype=np.int64)\n",
    "        \n",
    "        vector[0] = vocab.lookup_token(vocab._begin_seq_token)\n",
    "        \n",
    "        for i in range(len(text)):\n",
    "            vector[i+1] = vocab.lookup_token(text[i])\n",
    "        \n",
    "        vector[len(text) + 1] = vocab.lookup_token(vocab._end_seq_token)\n",
    "        \n",
    "        return vector\n",
    "    \n",
    "    def vectorize(self, source_text, target_text):\n",
    "        source_text = punct_regex.tokenize(source_text)\n",
    "        target_text = punct_regex.tokenize(target_text)\n",
    "        \n",
    "        source_vector = self.get_vector(source_text)\n",
    "        target_vector = self.get_vector(target_text, False, True)\n",
    "        \n",
    "        return source_vector, target_vector\n",
    "    \n",
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, text_df, vectorizer):\n",
    "        self.text_df = text_df\n",
    "        self._vectorizer = vectorizer\n",
    " \n",
    "        self.train_df = self.text_df[self.text_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    " \n",
    "        self.val_df = self.text_df[self.text_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    " \n",
    "        self.test_df = self.text_df[self.text_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    " \n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.validation_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    " \n",
    "        self.set_split('train')\n",
    " \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, dataset_csv):\n",
    "        text_df = pd.read_csv(dataset_csv)\n",
    "        train_subset = text_df[text_df.split=='train']\n",
    "        return cls(text_df, NMTVectorizer.from_dataframe(train_subset))\n",
    " \n",
    "    def set_split(self, split=\"train\"):\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "    \n",
    "    def get_vectorizer(self):\n",
    "        return self._vectorizer\n",
    " \n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        row = self._target_df.iloc[index]\n",
    " \n",
    "        source_vector, target_vector = self._vectorizer.vectorize(row.source_language, row.target_language)\n",
    "        \n",
    "        return {\"x_source\": source_vector,\n",
    "               \"y_target\": target_vector}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "e0GpHj2Mb9L1"
   },
   "outputs": [],
   "source": [
    "def get_batch_loader(dataset, batch_size):\n",
    "    data_indices = np.arange(dataset._target_size)    \n",
    "    np.random.shuffle(data_indices)\n",
    "    \n",
    "    data = []\n",
    "    for index in data_indices:\n",
    "        data.append(dataset[index])\n",
    "        \n",
    "    data_loader = DataLoader(data, batch_size=batch_size)\n",
    "        \n",
    "    return data_loader\n",
    "\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 80):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # create constant 'pe' matrix with values dependant on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = \\\n",
    "                math.cos(pos / (10000 ** (((2 * i) + 1)/d_model)))\n",
    "                \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    " \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # make embeddings relatively larger\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        #add constant to embedding\n",
    "        seq_len = x.size(1)\n",
    "        x = x + Variable(self.pe[:,:seq_len], requires_grad=False).cuda()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fY_5WxJmb_yz"
   },
   "outputs": [],
   "source": [
    "dataset = NMTDataset.load_dataset_and_make_vectorizer(\"../../PyTorchNLPBook/data/nmt/simplest_eng_fra.csv\")\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "padding_index = vectorizer.source_vocab.mask_index\n",
    "\n",
    "EMBEDDING_DIM = 512\n",
    "FF_DIM = 4\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 3\n",
    "DROPOUT = 0.1\n",
    "SOURCE_VOCAB_SIZE = len(vectorizer.source_vocab._token_to_idx)\n",
    "TARGET_VOCAB_SIZE = len(vectorizer.target_vocab._token_to_idx)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 3e-4\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "PRINT_EVERY = NUM_EPOCHS / 10\n",
    "\n",
    "dataset.set_split(\"train\")\n",
    "train_loader = get_batch_loader(dataset, BATCH_SIZE)\n",
    "\n",
    "dataset.set_split(\"val\")\n",
    "val_loader = get_batch_loader(dataset, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257,
     "referenced_widgets": [
      "f2acd4805050407187c0785735b27138",
      "3d5ba82a7748426b8712867e6a1cc76e",
      "5544ec4a278d4e57bab3b2492eff9d68",
      "68b9e54bd0ef4afa8b157660444dc403",
      "068f7b8d099a46feae0a59db5391f099",
      "369fb02389fa4b60bfd23f5afcdd5a10",
      "0d7f7413ccd249998070ea834214fa6a",
      "cd92db7909744ec080ffcadb4343c99c"
     ]
    },
    "id": "B4_g79m0lRI0",
    "outputId": "d030f97c-2080-4e04-a74f-800962477582"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55df53b3858b44388aafd826eb3901df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Train loss: 5.0105  Validation Loss: 4.0048\n",
      "Epoch: 5  Train loss: 2.6616  Validation Loss: 2.7817\n",
      "Epoch: 10 Train loss: 1.6908  Validation Loss: 2.3907\n",
      "Epoch: 15 Train loss: 1.1512  Validation Loss: 2.2675\n",
      "Epoch: 20 Train loss: 0.8499  Validation Loss: 2.2756\n",
      "Epoch: 25 Train loss: 0.6860  Validation Loss: 2.2951\n",
      "Epoch: 30 Train loss: 0.5662  Validation Loss: 2.4076\n",
      "Epoch: 35 Train loss: 0.4888  Validation Loss: 2.5013\n",
      "Epoch: 40 Train loss: 0.4424  Validation Loss: 2.5455\n",
      "Epoch: 45 Train loss: 0.4061  Validation Loss: 2.6160\n",
      "Epoch: 50 Train loss: 0.3711  Validation Loss: 2.6822\n"
     ]
    }
   ],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, emb_dim, dim_kqv):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        self.dim_kqv = dim_kqv\n",
    "        \n",
    "        self.wq = nn.Linear(emb_dim, dim_kqv)\n",
    "        self.wk = nn.Linear(emb_dim, dim_kqv)        \n",
    "        self.wv = nn.Linear(emb_dim, dim_kqv)\n",
    "        \n",
    "    def forward(self, q, k, v, mask):\n",
    "        queries = self.wq(q)\n",
    "        keys = self.wk(k)\n",
    "        values = self.wv(v)\n",
    "        \n",
    "        score = queries.bmm(keys.transpose(1, 2))     \n",
    "\n",
    "        score = torch.div(score, self.dim_kqv ** 0.5, rounding_mode='floor')\n",
    "        \n",
    "        if mask is not None:\n",
    "            score = score.masked_fill(mask == 0, -1e9)\n",
    "#             print(\"scaled score with mask:\")\n",
    "#             print(score)\n",
    "        \n",
    "        softmax = F.softmax(score, dim = -1)\n",
    "\n",
    "        return softmax.bmm(values)\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, emb_dim, dim_kqv):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [AttentionHead(emb_dim, dim_kqv) for _ in range(num_heads)]\n",
    "        )\n",
    "        \n",
    "        self.w0 = nn.Linear(num_heads * dim_kqv, emb_dim)\n",
    "        \n",
    "    def forward(self, q, k, v, mask):\n",
    "        attentions = [h(q, k, v, mask) for h in self.heads]\n",
    "        attentions = torch.cat(attentions, dim = -1)\n",
    "        out = self.w0(attentions)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, sublayer, dimension, dropout):\n",
    "        super(Residual, self).__init__()\n",
    "        self.sublayer = sublayer\n",
    "        self.norm = nn.LayerNorm(dimension)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, *tensors):\n",
    "        return self.dropout(self.norm(tensors[0] + self.sublayer(*tensors)))\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, emb_dim, ff_dim):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(emb_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, emb_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, residual_out):\n",
    "        return self.network(residual_out)\n",
    "    \n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, emb_dim, num_heads, ff_dim, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.dim_kqv = emb_dim // num_heads\n",
    "        \n",
    "        assert (self.dim_kqv * num_heads == emb_dim), \"Embedding size must be divisible by number of heads\" \n",
    "        \n",
    "        self.attention = Residual(\n",
    "            MultiHeadAttention(num_heads, emb_dim, self.dim_kqv),\n",
    "            dimension=emb_dim,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "    \n",
    "        self.feed_forward = Residual(\n",
    "            FeedForward(emb_dim, ff_dim),\n",
    "            dimension=emb_dim,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        \n",
    "    def forward(self, src, mask):\n",
    "        src = self.attention(src, src, src, mask)\n",
    "        out = self.feed_forward(src)\n",
    "        return out\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 emb_dim, \n",
    "                 num_heads, \n",
    "                 ff_dim, \n",
    "                 num_layers, \n",
    "                 src_vocab_size,\n",
    "                 padding_index,\n",
    "                 dropout):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(emb_dim,\n",
    "                         num_heads,\n",
    "                         ff_dim,\n",
    "                         dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.embedding = nn.Embedding(src_vocab_size, emb_dim, padding_idx=0)\n",
    "        self.pe = PositionalEncoder(emb_dim)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src)\n",
    "        \n",
    "        src = self.pe(src)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            src = layer(src, None)\n",
    "            \n",
    "        return src\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, emb_dim, num_heads, ff_dim, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.dim_kqv = emb_dim // num_heads\n",
    "        \n",
    "        assert (self.dim_kqv * num_heads == emb_dim), \"Embedding size must be divisible by number of heads\"\n",
    "        \n",
    "        self.attention_1 = Residual(\n",
    "            MultiHeadAttention(num_heads, emb_dim, self.dim_kqv),\n",
    "            dimension=emb_dim,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.attention_2 = Residual(\n",
    "            MultiHeadAttention(num_heads, emb_dim, self.dim_kqv),\n",
    "            dimension=emb_dim,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.feed_forward = Residual(\n",
    "            FeedForward(emb_dim, ff_dim),\n",
    "            dimension=emb_dim,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "    def forward(self, trg, memory, mask):\n",
    "        query = self.attention_1(trg, trg, trg, mask)\n",
    "        attentions = self.attention_2(query, memory, memory, None)\n",
    "        out = self.feed_forward(attentions)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 emb_dim, \n",
    "                 num_heads, \n",
    "                 ff_dim, \n",
    "                 num_layers, \n",
    "                 out_size, \n",
    "                 padding_index,\n",
    "                 dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderLayer(emb_dim, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.embedding = nn.Embedding(out_size, emb_dim, padding_idx=padding_index)\n",
    "        self.pe = PositionalEncoder(emb_dim)\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        batch_size, seq_len = trg.shape[0], trg.shape[1]\n",
    "        mask = torch.tril(torch.ones(batch_size, seq_len, seq_len))\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, trg, encoder_out):\n",
    "        trg = self.embedding(trg)\n",
    "        \n",
    "        trg = self.pe(trg)\n",
    "\n",
    "        mask = self.make_trg_mask(trg).to(trg.get_device())\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            trg = layer(trg, encoder_out, mask)\n",
    "            \n",
    "        # return self.lin(trg)\n",
    "        return trg\n",
    "\n",
    "class VanillaTransformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 emb_dim, \n",
    "                 num_heads, \n",
    "                 ff_dim, \n",
    "                 num_layers, \n",
    "                 src_vocab_size, \n",
    "                 trg_vocab_size,\n",
    "                 device,\n",
    "                 padding_index,\n",
    "                 dropout):\n",
    "        super(VanillaTransformer, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(emb_dim, \n",
    "                               num_heads, \n",
    "                               ff_dim,\n",
    "                               num_layers, \n",
    "                               src_vocab_size,\n",
    "                               padding_index,\n",
    "                               dropout).to(device)\n",
    "        \n",
    "        self.decoder = Decoder(emb_dim,\n",
    "                               num_heads,\n",
    "                               ff_dim, \n",
    "                               num_layers,\n",
    "                               trg_vocab_size,\n",
    "                               padding_index,\n",
    "                               dropout).to(device)\n",
    "\n",
    "        self.lin = nn.Linear(emb_dim, trg_vocab_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, src, trg):\n",
    "        encoder_out = self.encoder(src)\n",
    "\n",
    "        decoder_out = self.decoder(trg, encoder_out)\n",
    "        \n",
    "        out = self.lin(decoder_out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "model = VanillaTransformer(EMBEDDING_DIM,\n",
    "                           NUM_HEADS,\n",
    "                           FF_DIM,\n",
    "                           NUM_LAYERS,\n",
    "                           SOURCE_VOCAB_SIZE,\n",
    "                           TARGET_VOCAB_SIZE,\n",
    "                           device,\n",
    "                           padding_index,\n",
    "                           DROPOUT).to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_func = nn.CrossEntropyLoss(ignore_index=padding_index)\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS), position = 0, leave = True):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for batch_index, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        src = batch['x_source']\n",
    "        trg = batch['y_target']\n",
    "        \n",
    "        y_pred = model(src.to(device), trg[:, :-1].to(device))\n",
    "        y_pred = y_pred.reshape(-1, y_pred.shape[2])\n",
    "        \n",
    "        loss = loss_func(y_pred, trg[:, 1:].reshape(-1).to(device))\n",
    "        loss.backward()\n",
    "\n",
    "        running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "        optimizer.step()\n",
    "\n",
    "    val_running_loss = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    for batch_index, batch in enumerate(val_loader):\n",
    "        src = batch['x_source']\n",
    "        trg = batch['y_target']\n",
    "        \n",
    "        y_pred = model(src.to(device), trg[:, :-1].to(device))\n",
    "        y_pred = y_pred.reshape(-1, y_pred.shape[2])\n",
    "        \n",
    "        loss = loss_func(y_pred, trg[:, 1:].reshape(-1).to(device))\n",
    "        \n",
    "        val_running_loss += (loss.item() - val_running_loss) / (batch_index + 1)\n",
    "        \n",
    "    if epoch == 0 or (epoch + 1) % PRINT_EVERY == 0:\n",
    "        print('Epoch: {:<2} Train loss: {:0.4f}  Validation Loss: {:0.4f}'.format(epoch + 1 , running_loss, val_running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwU53dxnRNHr",
    "outputId": "42df8606-eda7-450f-d1ff-a631a56850af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: you 're a prude\n",
      "Target: vous êtes un puritain\n",
      "Prediction: vous êtes êtes puritaine puritaine\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "    return text\n",
    "\n",
    "def translate_sentence(source_sentence, target_sentence, classifier, vectorizer, decision_threshold=0.5):\n",
    "    source_sentence = preprocess_text(source_sentence)\n",
    "    target_sentence = preprocess_text(target_sentence)\n",
    "    \n",
    "    source_vector, target_vector = vectorizer.vectorize(source_sentence, target_sentence)\n",
    "\n",
    "    source_tensor = torch.tensor(source_vector).unsqueeze(0)\n",
    "    target_tensor = torch.tensor(target_vector).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        result = classifier(source_tensor.to(device), target_tensor[:, :-1].to(device))\n",
    "        result = result.reshape(-1, result.shape[2])\n",
    "        result = F.softmax(result, -1)\n",
    "\n",
    "    indices = torch.argmax(result, 1)\n",
    "    word_arr = []\n",
    "    for i in range(indices.shape[0]):\n",
    "        index = indices[i].item()\n",
    "        if vectorizer.target_vocab._idx_to_token[index] == \"<END>\":\n",
    "            break\n",
    "        word_arr.append(vectorizer.target_vocab._idx_to_token[index])\n",
    "\n",
    "    return ' '.join(word_arr)\n",
    "\n",
    "source_sentence = \"you 're a prude\"\n",
    "target_sentence = \"vous êtes un puritain\"\n",
    "\n",
    "model = model.to(device)\n",
    "prediction = translate_sentence(source_sentence, target_sentence, model, dataset.get_vectorizer())\n",
    "\n",
    "print(\"Source:\", source_sentence)\n",
    "print(\"Target:\", target_sentence)\n",
    "print(\"Prediction:\", prediction)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vanilla_transformer_nmt",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "068f7b8d099a46feae0a59db5391f099": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0d7f7413ccd249998070ea834214fa6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "369fb02389fa4b60bfd23f5afcdd5a10": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d5ba82a7748426b8712867e6a1cc76e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5544ec4a278d4e57bab3b2492eff9d68": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_369fb02389fa4b60bfd23f5afcdd5a10",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_068f7b8d099a46feae0a59db5391f099",
      "value": 50
     }
    },
    "68b9e54bd0ef4afa8b157660444dc403": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd92db7909744ec080ffcadb4343c99c",
      "placeholder": "​",
      "style": "IPY_MODEL_0d7f7413ccd249998070ea834214fa6a",
      "value": " 50/50 [1:14:17&lt;00:00, 89.16s/it]"
     }
    },
    "cd92db7909744ec080ffcadb4343c99c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2acd4805050407187c0785735b27138": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5544ec4a278d4e57bab3b2492eff9d68",
       "IPY_MODEL_68b9e54bd0ef4afa8b157660444dc403"
      ],
      "layout": "IPY_MODEL_3d5ba82a7748426b8712867e6a1cc76e"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
