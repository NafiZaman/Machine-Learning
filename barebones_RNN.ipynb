{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: tensor([[[ 0.0037,  0.1530,  0.7012, -0.1402,  0.1944]],\n",
      "\n",
      "        [[ 0.3124, -0.1422,  0.5204, -0.2674,  0.0915]]],\n",
      "       grad_fn=<StackBackward>), \n",
      "\n",
      "out shape: torch.Size([2, 1, 5]), \n",
      "\n",
      "hx: tensor([[[ 0.3124, -0.1422,  0.5204, -0.2674,  0.0915]]],\n",
      "       grad_fn=<StackBackward>), \n",
      "\n",
      "hx shape: torch.Size([1, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "n_in, n_out = 3, 5\n",
    "\n",
    "inpt = torch.randn([6])\n",
    "\n",
    "inpt = inpt.view(2, 1, 3)\n",
    "\n",
    "# print(f'inpt: {inpt}, inpt shape: {inpt.shape}')\n",
    "\n",
    "vanilla_rnn = nn.RNN(n_in, n_out)\n",
    "out, hx = vanilla_rnn(inpt)\n",
    "\n",
    "print(f'out: {out}, \\n\\nout shape: {out.shape}, \\n\\nhx: {hx}, \\n\\nhx shape: {hx.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 Parameter containing:\n",
      "tensor([[ 0.1633, -0.1743, -0.0326],\n",
      "        [-0.0403,  0.0648, -0.0018],\n",
      "        [ 0.3909,  0.1392, -0.1665],\n",
      "        [-0.2701, -0.0750, -0.1929],\n",
      "        [-0.1433,  0.0214,  0.2666]], requires_grad=True) torch.Size([5, 3])\n",
      "weight_hh_l0 Parameter containing:\n",
      "tensor([[ 0.2431, -0.4372,  0.2772,  0.1249,  0.4242],\n",
      "        [ 0.2952, -0.4075, -0.4252, -0.2157,  0.3927],\n",
      "        [-0.0745,  0.1914, -0.2078,  0.4388, -0.1892],\n",
      "        [ 0.3354,  0.0053, -0.2356,  0.2299, -0.2374],\n",
      "        [ 0.1315, -0.1291, -0.0490, -0.4299, -0.2132]], requires_grad=True) torch.Size([5, 5])\n",
      "bias_ih_l0 Parameter containing:\n",
      "tensor([ 0.2427, -0.1087,  0.4454,  0.3585, -0.0209], requires_grad=True) torch.Size([5])\n",
      "bias_hh_l0 Parameter containing:\n",
      "tensor([-0.2985,  0.2723,  0.1388, -0.2891,  0.2905], requires_grad=True) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for name, param in vanilla_rnn.named_parameters():\n",
    "    print(name, param, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wih shape: torch.Size([5, 3]), whh shape = torch.Size([5, 5])bih shape: torch.Size([5]), bhh shape = torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "wih = vanilla_rnn.weight_ih_l0\n",
    "whh = vanilla_rnn.weight_hh_l0\n",
    "bih = vanilla_rnn.bias_ih_l0\n",
    "bhh = vanilla_rnn.bias_hh_l0\n",
    "\n",
    "print(f'wih shape: {wih.shape}, whh shape = {whh.shape}\\\n",
    "bih shape: {bih.shape}, bhh shape = {bhh.shape}')\n",
    "\n",
    "input = inpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tanh = nn.Tanh()\n",
    "output = []\n",
    "hid = torch.zeros(1, 5, dtype = torch.float32)\n",
    "# print(hid)\n",
    "for i in range(input.shape[0]):\n",
    "    x = input[i]\n",
    "    i1 = x @ torch.transpose(wih, 0, 1) + bih\n",
    "    h1 = hid @ torch.transpose(whh, 0, 1) + bhh\n",
    "    \n",
    "    hid = tanh(i1+h1)\n",
    "    \n",
    "    output.append(hid)\n",
    "\n",
    "hid = hid.unsqueeze(0)\n",
    "output = torch.stack(output, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch results: \n",
      "out: tensor([[[ 0.0037,  0.1530,  0.7012, -0.1402,  0.1944]],\n",
      "\n",
      "        [[ 0.3124, -0.1422,  0.5204, -0.2674,  0.0915]]],\n",
      "       grad_fn=<StackBackward>), \n",
      "\n",
      "out shape: torch.Size([2, 1, 5]), \n",
      "\n",
      "hx: tensor([[[ 0.3124, -0.1422,  0.5204, -0.2674,  0.0915]]],\n",
      "       grad_fn=<StackBackward>), \n",
      "\n",
      "hx shape: torch.Size([1, 1, 5])\n",
      "\n",
      "My results: \n",
      "out: tensor([[[ 0.0037,  0.1530,  0.7012, -0.1402,  0.1944]],\n",
      "\n",
      "        [[ 0.3124, -0.1422,  0.5204, -0.2674,  0.0915]]],\n",
      "       grad_fn=<StackBackward>), \n",
      "\n",
      "out shape: torch.Size([2, 1, 5]), \n",
      "\n",
      "hx: tensor([[[ 0.3124, -0.1422,  0.5204, -0.2674,  0.0915]]],\n",
      "       grad_fn=<UnsqueezeBackward0>), \n",
      "\n",
      "hx shape: torch.Size([1, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "print(\"Pytorch results: \")\n",
    "print(f'out: {out}, \\n\\nout shape: {out.shape}, \\n\\nhx: {hx}, \\n\\nhx shape: {hx.shape}')\n",
    "print()\n",
    "\n",
    "print(\"My results: \")\n",
    "print(f'out: {output}, \\n\\nout shape: {output.shape}, \\n\\nhx: {hid}, \\n\\nhx shape: {hid.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **BIDIRECTION** Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inpt: tensor([[[ 0.9042,  0.1181,  1.8941]],\n",
      "\n",
      "        [[-0.4229,  0.7431,  0.0756]]]), inpt shape: torch.Size([2, 1, 3])\n",
      "out: tensor([[[ 0.1374, -0.0571, -0.7966, -0.5038,  0.7501, -0.5088, -0.3542,\n",
      "          -0.6363, -0.7504, -0.6143]],\n",
      "\n",
      "        [[-0.8717, -0.4163, -0.7654,  0.1273,  0.3883,  0.2443,  0.1815,\n",
      "           0.0180, -0.7577, -0.6236]]], grad_fn=<CatBackward>), \n",
      "\n",
      "out shape: torch.Size([2, 1, 10]), \n",
      "\n",
      "hx: tensor([[[-0.8717, -0.4163, -0.7654,  0.1273,  0.3883]],\n",
      "\n",
      "        [[-0.5088, -0.3542, -0.6363, -0.7504, -0.6143]]],\n",
      "       grad_fn=<StackBackward>), \n",
      "\n",
      "hx shape: torch.Size([2, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(1)\n",
    "n_in, n_out = 3, 5\n",
    "\n",
    "inpt = torch.randn([6])\n",
    "\n",
    "inpt = inpt.view(2, 1, 3)\n",
    "\n",
    "print(f'inpt: {inpt}, inpt shape: {inpt.shape}')\n",
    "\n",
    "vanilla_rnn = nn.RNN(n_in, n_out,bidirectional = True)\n",
    "out, hx = vanilla_rnn(inpt)\n",
    "\n",
    "print(f'out: {out}, \\n\\nout shape: {out.shape}, \\n\\nhx: {hx}, \\n\\nhx shape: {hx.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 Parameter containing:\n",
      "tensor([[ 0.2051, -0.3830,  0.3263],\n",
      "        [ 0.1340, -0.0514,  0.2051],\n",
      "        [-0.3184, -0.0978,  0.0044],\n",
      "        [-0.2584, -0.1143, -0.1929],\n",
      "        [ 0.4262,  0.3799,  0.3857]], requires_grad=True) torch.Size([5, 3])\n",
      "\n",
      "weight_hh_l0 Parameter containing:\n",
      "tensor([[ 0.3655, -0.4283,  0.1496,  0.1648, -0.3280],\n",
      "        [ 0.1813, -0.2427,  0.0711,  0.1481,  0.3859],\n",
      "        [-0.2346, -0.3519,  0.4138,  0.1877,  0.2174],\n",
      "        [ 0.1610, -0.1583,  0.2690, -0.3904,  0.0622],\n",
      "        [ 0.2022,  0.3056, -0.2233, -0.3023,  0.1676]], requires_grad=True) torch.Size([5, 5])\n",
      "\n",
      "bias_ih_l0 Parameter containing:\n",
      "tensor([-0.3552, -0.3717, -0.4022, -0.2169, -0.0854], requires_grad=True) torch.Size([5])\n",
      "\n",
      "bias_hh_l0 Parameter containing:\n",
      "tensor([-0.2648, -0.1891, -0.3960,  0.2749, -0.1024], requires_grad=True) torch.Size([5])\n",
      "\n",
      "weight_ih_l0_reverse Parameter containing:\n",
      "tensor([[-0.2822,  0.1164, -0.3344],\n",
      "        [ 0.3130,  0.2572, -0.4395],\n",
      "        [-0.3510, -0.2949, -0.2421],\n",
      "        [ 0.0558, -0.4422, -0.3315],\n",
      "        [ 0.2042, -0.1465, -0.1780]], requires_grad=True) torch.Size([5, 3])\n",
      "\n",
      "weight_hh_l0_reverse Parameter containing:\n",
      "tensor([[-0.3700,  0.1813,  0.0316, -0.1729, -0.2739],\n",
      "        [ 0.0951,  0.1217,  0.1985,  0.1329, -0.0682],\n",
      "        [-0.3462,  0.2847, -0.0038, -0.2972,  0.3857],\n",
      "        [ 0.2493, -0.3515, -0.2233, -0.1522, -0.2582],\n",
      "        [ 0.2088, -0.3190,  0.4156, -0.1848,  0.2640]], requires_grad=True) torch.Size([5, 5])\n",
      "\n",
      "bias_ih_l0_reverse Parameter containing:\n",
      "tensor([ 0.0152, -0.1967,  0.2986, -0.3412, -0.2366], requires_grad=True) torch.Size([5])\n",
      "\n",
      "bias_hh_l0_reverse Parameter containing:\n",
      "tensor([ 0.0536,  0.3548, -0.1916, -0.2723, -0.2855], requires_grad=True) torch.Size([5])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in vanilla_rnn.named_parameters():\n",
    "    print(name, param, param.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "wih = vanilla_rnn.weight_ih_l0\n",
    "whh = vanilla_rnn.weight_hh_l0\n",
    "bih = vanilla_rnn.bias_ih_l0\n",
    "bhh = vanilla_rnn.bias_hh_l0\n",
    "\n",
    "wihr = vanilla_rnn.weight_ih_l0_reverse\n",
    "whhr = vanilla_rnn.weight_hh_l0_reverse\n",
    "bihr = vanilla_rnn.bias_ih_l0_reverse\n",
    "bhhr = vanilla_rnn.bias_hh_l0_reverse\n",
    "\n",
    "input = inpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8717, -0.4163, -0.7654,  0.1273,  0.3883]], requires_grad=True)\n",
      "tensor([[-0.5088, -0.3542, -0.6363, -0.7504, -0.6143]], requires_grad=True)\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "tensor([[-0.8717, -0.4163, -0.7654,  0.1273,  0.3883]], grad_fn=<TanhBackward>)\n",
      "tensor([[-0.5088, -0.3542, -0.6363, -0.7504, -0.6143]], grad_fn=<TanhBackward>)\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(hx.shape[0]):\n",
    "        print(hx[i])\n",
    "print(\"--------------------------------\")\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "tanh = nn.Tanh()\n",
    "output = []\n",
    "hid_forward = torch.zeros(1, 5, dtype = torch.float32)\n",
    "hid_reverse = torch.zeros(1, 5, dtype = torch.float32)\n",
    "\n",
    "# Forward\n",
    "for i in range(input.shape[0]):\n",
    "    x = input[i]\n",
    "    \n",
    "    i_forward = x @ torch.transpose(wih, 0, 1) + bih\n",
    "    h_forward = hid_forward @ torch.transpose(whh, 0, 1) + bhh\n",
    "    hid_forward = tanh(i_forward + h_forward)\n",
    "    \n",
    "\n",
    "# Reverse\n",
    "reverse_input = torch.flip(input, (0, 1))\n",
    "    \n",
    "for i in range(reverse_input.shape[0]):\n",
    "    x = reverse_input[i]\n",
    "    \n",
    "    i_reverse = x @ torch.transpose(wihr, 0, 1) + bihr\n",
    "    h_reverse = hid_reverse @ torch.transpose(whhr, 0, 1) + bhhr\n",
    "    hid_reverse = tanh(i_reverse + h_reverse)\n",
    "    \n",
    "print(hid_forward)\n",
    "print(hid_reverse)\n",
    "print(\"-----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Multi-layer** RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: tensor([[[-0.0775,  0.1719,  0.4814,  0.5731, -0.0162]],\n",
      "\n",
      "        [[-0.2183,  0.0993,  0.7477,  0.5326, -0.0862]]],\n",
      "       grad_fn=<StackBackward>)\n",
      "\n",
      "out shape: torch.Size([2, 1, 5])\n",
      "\n",
      "hx: tensor([[[ 0.0374, -0.0655,  0.9111,  0.6196, -0.6483]],\n",
      "\n",
      "        [[-0.2183,  0.0993,  0.7477,  0.5326, -0.0862]]],\n",
      "       grad_fn=<StackBackward>)\n",
      "\n",
      "hx shape: torch.Size([2, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "n_in, n_out = 3, 5\n",
    "n_layers = 2\n",
    "inpt = torch.tensor([1,2,3,4,5,6], dtype = torch.float32)\n",
    "\n",
    "inpt = inpt.view(2, 1, 3)\n",
    "\n",
    "bidirectional_rnn = nn.RNN(n_in, n_out, n_layers)\n",
    "\n",
    "out, hx = bidirectional_rnn(inpt)\n",
    "\n",
    "print(f'out: {out}\\n\\nout shape: {out.shape}\\n\\nhx: {hx}\\n\\nhx shape: {hx.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 Parameter containing:\n",
      "tensor([[ 0.2304, -0.1974, -0.0867],\n",
      "        [ 0.2099, -0.4210,  0.2682],\n",
      "        [-0.0920,  0.2275,  0.0622],\n",
      "        [-0.0548,  0.1240,  0.0221],\n",
      "        [ 0.1633, -0.1743, -0.0326]], requires_grad=True) torch.Size([5, 3])\n",
      "\n",
      "weight_hh_l0 Parameter containing:\n",
      "tensor([[-0.0403,  0.0648, -0.0018,  0.3909,  0.1392],\n",
      "        [-0.1665, -0.2701, -0.0750, -0.1929, -0.1433],\n",
      "        [ 0.0214,  0.2666,  0.2431, -0.4372,  0.2772],\n",
      "        [ 0.1249,  0.4242,  0.2952, -0.4075, -0.4252],\n",
      "        [-0.2157,  0.3927, -0.0745,  0.1914, -0.2078]], requires_grad=True) torch.Size([5, 5])\n",
      "\n",
      "bias_ih_l0 Parameter containing:\n",
      "tensor([ 0.4388, -0.1892,  0.3354,  0.0053, -0.2356], requires_grad=True) torch.Size([5])\n",
      "\n",
      "bias_hh_l0 Parameter containing:\n",
      "tensor([ 0.2299, -0.2374,  0.1315, -0.1291, -0.0490], requires_grad=True) torch.Size([5])\n",
      "\n",
      "weight_ih_l1 Parameter containing:\n",
      "tensor([[-0.4299, -0.2132,  0.2427, -0.1087,  0.4454],\n",
      "        [ 0.3585, -0.0209, -0.2985,  0.2723,  0.1388],\n",
      "        [-0.2891,  0.2905,  0.2715,  0.3966, -0.2507],\n",
      "        [-0.0736, -0.0087,  0.0653, -0.3394, -0.3174],\n",
      "        [ 0.2433, -0.1049,  0.2185,  0.0255,  0.1468]], requires_grad=True) torch.Size([5, 5])\n",
      "\n",
      "weight_hh_l1 Parameter containing:\n",
      "tensor([[ 0.0983,  0.1626,  0.2217, -0.4142,  0.2251],\n",
      "        [-0.3144, -0.3374,  0.0272, -0.0762,  0.2627],\n",
      "        [-0.2590, -0.3976,  0.3255, -0.0663,  0.2515],\n",
      "        [ 0.1438, -0.3354,  0.0898,  0.1074, -0.2994],\n",
      "        [-0.2122,  0.1525,  0.0801, -0.1902, -0.1354]], requires_grad=True) torch.Size([5, 5])\n",
      "\n",
      "bias_ih_l1 Parameter containing:\n",
      "tensor([ 0.4096, -0.0827,  0.2521,  0.1936, -0.2891], requires_grad=True) torch.Size([5])\n",
      "\n",
      "bias_hh_l1 Parameter containing:\n",
      "tensor([-0.3803,  0.4293,  0.0234,  0.3065,  0.0927], requires_grad=True) torch.Size([5])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in bidirectional_rnn.named_parameters():\n",
    "    print(name, param, param.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wih_l0 = bidirectional_rnn.weight_ih_l0\n",
    "wih_l1 = bidirectional_rnn.weight_ih_l1\n",
    "\n",
    "whh_l0 = bidirectional_rnn.weight_hh_l0\n",
    "whh_l1 = bidirectional_rnn.weight_hh_l1\n",
    "\n",
    "bih_l0 = bidirectional_rnn.bias_ih_l0\n",
    "bih_l1 = bidirectional_rnn.bias_ih_l1\n",
    "\n",
    "bhh_l0 = bidirectional_rnn.bias_hh_l0\n",
    "bhh_l1 = bidirectional_rnn.bias_hh_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: tensor([[[-0.0775,  0.1719,  0.4814,  0.5731, -0.0162]],\n",
      "\n",
      "        [[-0.2183,  0.0993,  0.7477,  0.5326, -0.0862]]],\n",
      "       grad_fn=<StackBackward>) torch.Size([2, 1, 5])\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "final output: tensor([[[-0.0775,  0.1719,  0.4814,  0.5731, -0.0162]],\n",
      "\n",
      "        [[-0.2183,  0.0993,  0.7477,  0.5326, -0.0862]]],\n",
      "       grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(f'out: {out} {out.shape}')\n",
    "#     print(f'nhx: {hx} {hx.shape}')\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "input = inpt\n",
    "\n",
    "tanh = nn.Tanh()\n",
    "hid = torch.zeros(1, n_out, dtype = torch.float32)\n",
    "output = []\n",
    "\n",
    "\n",
    "for i in range(input.shape[0]):\n",
    "    x = input[i]\n",
    "    \n",
    "    i = x @ torch.transpose(wih_l0, 0, 1) + bih_l0\n",
    "    h = hid @ torch.transpose(whh_l0, 0, 1) + bhh_l0\n",
    "    \n",
    "    hid = tanh(i + h)\n",
    "    \n",
    "    output.append(hid)\n",
    "\n",
    "output = torch.stack(output, dim = 0)\n",
    "\n",
    "final_output = []\n",
    "hid = torch.zeros(1, n_out, dtype = torch.float32)\n",
    "for i in range(output.shape[0]):\n",
    "    x = output[i]\n",
    "    \n",
    "    i = x @ torch.transpose(wih_l1, 0, 1) + bih_l1\n",
    "    h = hid @ torch.transpose(whh_l1, 0, 1) + bhh_l1\n",
    "    \n",
    "    hid = tanh(i + h)\n",
    "    \n",
    "    final_output.append(hid)\n",
    "\n",
    "final_output = torch.stack(final_output, dim = 0)\n",
    "print(f'final output: {final_output}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
